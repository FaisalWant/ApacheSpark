{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Apache spark_3",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FaisalWant/ApacheSpark/blob/master/Apache_spark_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwqKU-PhhC58"
      },
      "source": [
        "#[Apache Spark 3.0.0 with Google Colab](http://apache.osuosl.org/spark/spark-3.0.0/)\n",
        "\n",
        "**Author: Faisal Want**\n",
        "\n",
        "This is the working google collaboratory notebook example of setting up  recently release spark 3.0.0 in google colab. \n",
        "\n",
        "* Installing Java in the Google Colaboratory\n",
        "* Setting up Spark 3.0 in the Google Colaboratory\n",
        "* A test example\n",
        "\n",
        "**References:**\n",
        "\n",
        "1. http://apache.osuosl.org/spark/spark-3.0.0/\n",
        "2. https://medium.com/@sushantgautam_930/apache-spark-in-google-collaboratory-in-3-steps-e0acbba654e6\n",
        "3. https://notebooks.gesis.org/binder/jupyter/user/databricks-koalas-kuv5qckt/notebooks/docs/source/getting_started/10min.ipynb\n",
        "4. https://medium.com/@amjadraza24/getting-started-spark3-0-0-with-google-colab-9796d350d78\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spark directory -- https://apache.osuosl.org/spark/"
      ],
      "metadata": {
        "id": "eQDoLXCYq2TF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MZdDu9LhLwN"
      },
      "source": [
        "# Run below commands\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://apache.osuosl.org/spark/spark-3.3.0/spark-3.3.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.3.0-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKbDZzlDe_aT"
      },
      "source": [
        "!ls -a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sit9TX0chlNF"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.0-bin-hadoop3\""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da7M2Wi1jC1c"
      },
      "source": [
        "## Spark Installation test\n",
        "Lets test the installation of spark in our google colab environment. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y18KVg34jkXj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85b9532b-938c-4d02-a437-edeea397d390"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "# Test the spark \n",
        "df = spark.createDataFrame([{\"hello\": \"world\"} for x in range(1000)])\n",
        "\n",
        "df.show(3, False)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|hello|\n",
            "+-----+\n",
            "|world|\n",
            "|world|\n",
            "|world|\n",
            "+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe6Mlcs29vX-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07a9e131-67ee-4e52-9890-b4eb390f7780"
      },
      "source": [
        "# Check the pyspark version\n",
        "import pyspark\n",
        "print(pyspark.__version__)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjUld8S6bRHz"
      },
      "source": [
        "# Conclusions\n",
        "\n",
        "In this notebook, we learned\n",
        "\n",
        "* Running spark 3.0.0-preview2 in Google Colab\n",
        "* Running pysprak3.0.0dev2\n"
      ]
    }
  ]
}